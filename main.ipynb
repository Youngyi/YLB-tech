{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索\n",
    "加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import para\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print(t)\n",
    "for i in range(para.machine_num):\n",
    "    file_path = para.train_data +  '{0:03d}'.format(i+2) + '/201807.csv'\n",
    "    with open(file_path,'r') as file:\n",
    "        data = csv.reader(file)\n",
    "        data.__next__()\n",
    "        full_data = []\n",
    "        p_miss_data = []\n",
    "        for record in data:\n",
    "            if any([r==''for r in record]):\n",
    "                p_miss_data.append(record)\n",
    "            else:\n",
    "                full_data.append(record)\n",
    "        raw_data_str = full_data\n",
    "    \n",
    "    break\n",
    "    \n",
    "# record to be filled\n",
    "file_path = para.train_data+'template_submit_result.csv'\n",
    "all_miss_data = []\n",
    "with open(file_path,'r') as file:\n",
    "    data = csv.reader(file)\n",
    "    data.__next__()\n",
    "    for record in data:\n",
    "        if record[1] == '1':\n",
    "            all_miss_data.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无缺失字段记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "t = ['M'] + ['i4'] + ['f4']*15+['i4']+['f4']*3+['i4']+['f4']*26+['i4']+['f4']*5+['i4']+['f4']*12+['i4']+['f4']*2\n",
    "\n",
    "raw_data_str = np.array(raw_data_str)\n",
    "raw_data = []\n",
    "\n",
    "for i in range(70):\n",
    "    s = raw_data_str[:,i].astype(t[i])\n",
    "    if i != 0 and i !=1:\n",
    "        plt.figure()\n",
    "        plt.hist(s)\n",
    "        plt.xlabel('var num {0}, type {5}, min {1:.2f}, max {2:.2f}, mean {3:.2f}, std {4:.2f}'.format(i-1,np.min(s),np.max(s),np.mean(s),np.std(s),t[i]))\n",
    "        plt.show()\n",
    "    raw_data.append(s)\n",
    "#     print(s[0],s.dtype)\n",
    "\n",
    "# print(raw_data[0],raw_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时序性测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16,8))\n",
    "for i in range(2,70):\n",
    "    plt.plot(raw_data[i],label=str(i-1))\n",
    "    plt.xlabel('var'+str(i-1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有缺失字段记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "p_miss_count = [0 for _ in range(70)]\n",
    "p_miss_total = len(p_miss_data)\n",
    "# print(p_miss_total)\n",
    "for r in p_miss_data:\n",
    "    for i in range(len(r)):\n",
    "        if r[i]=='':\n",
    "            p_miss_count[i]+=1\n",
    "p_miss_count = np.array(p_miss_count)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(np.array(range(70)),p_miss_count/p_miss_total)\n",
    "plt.show()\n",
    "\n",
    "f_miss_t = []    \n",
    "p_miss_t = []\n",
    "for record in all_miss_data:\n",
    "    flag = False\n",
    "    for p_r in p_miss_data:\n",
    "        if record[0]==p_r[0]:\n",
    "            flag = True\n",
    "            break\n",
    "    if flag:\n",
    "        p_miss_t.append(record[0])\n",
    "    else:\n",
    "        f_miss_t.append(record[0])    \n",
    "plt.figure(figsize=(16,8))\n",
    "# plt.plot(raw_data[0],[1 for _ in range(len(raw_data[0]))],'b.',label='full')\n",
    "plt.plot(np.array(p_miss_t,dtype='M'),[0.9 for _ in range(len(p_miss_t))],'r.',label='p_miss')\n",
    "plt.plot(np.array(f_miss_t,dtype='M'),[0.8 for _ in range(len(f_miss_t))],'g.',label='f_miss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预处理\n",
    "1. 对float类型做standardization (x-mean)/std \n",
    "2. 对int，book类型做one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# class used for pre-process data \n",
    "class preproc:\n",
    "    def __init__(self, data, types):\n",
    "        self.features = [True if t=='f4' else False for t in types] # 68个字段预处理分类操作\n",
    "        self.continuous, self.discrete = self.classify(data)\n",
    "        self.proc_cont = self.standardization(self.continuous)\n",
    "        self.proc_disc = self.one_hot(self.discrete)\n",
    "        \n",
    "    def classify(self, data):\n",
    "        return data[:,self.features], data[:,np.logical_not(self.features)]\n",
    "        \n",
    "    def standardization(self, data):\n",
    "        self.stda = StandardScaler()\n",
    "        return self.stda.fit_transform(data)\n",
    "        \n",
    "    def one_hot(self,data):\n",
    "        self.enc = OneHotEncoder()\n",
    "        return self.enc.fit_transform(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "data = np.array(raw_data).T[:,2:]\n",
    "pp = preproc(data,t[2:])\n",
    "inputs = np.concatenate((pp.proc_cont,pp.proc_disc.todense()),axis=1)\n",
    "print(inputs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run exp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "import pickle\n",
    "import torch\n",
    "dl = DataLoader()\n",
    "machine_num = 0 # 0号为001，1号为002，以此类推\n",
    "import para\n",
    "raw_data = dl(para.train_data,machine_num) #加载数据\n",
    "\n",
    "data = raw_data[:,1:] #移除时间列\n",
    "with open(\"meta.pkl\",'rb') as file:\n",
    "    pp = pickle.loads(file.read())\n",
    "    print('加载预处理meta完成。',flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pp.transform(torch.tensor(data[0:10].astype('f4'))) #预处理输出\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "rnn = nn.LSTM(input_size=141, hidden_size=256, bidirectional=True) #input_size, hidden_size, num_layers\n",
    "# input: seq_len, batch, input_size\n",
    "inputs = inputs.reshape(10,1,141).float()\n",
    "h0 = torch.randn(2, 1, 256)#num_layers * num_directions, batch, hidden_size\n",
    "c0 = torch.randn(2, 1, 256)#num_layers * num_directions, batch, hidden_size\n",
    "output, (hn, cn) = rnn(inputs, (h0, c0)) # output: seq_len, batch, num_directions * hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTMCell(141, 256)\n",
    "hx = torch.randn(1, 256)\n",
    "cx = torch.randn(1, 256)\n",
    "output = []\n",
    "for i in range(10):\n",
    "    hx, cx = rnn(inputs[i], (hx, cx))\n",
    "    output.append(hx)\n",
    "    print(hx.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import para\n",
    "i = 1\n",
    "file_path = para.train_data +  '{0:03d}'.format(i) + '/201807.csv'\n",
    "with open(file_path,'r') as file:\n",
    "    with open('small.csv','w') as output:\n",
    "        i = 0\n",
    "        while i<201:\n",
    "            output.write(file.readline()+'\\n')\n",
    "            i+=1\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt('small.csv',dtype=np.str,delimiter=',',skiprows=1)\n",
    "print(data[0])\n",
    "data = torch.tensor(data[:,1:].astype('f4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "import pickle\n",
    "import torch\n",
    "print(data.shape)\n",
    "with open(\"meta.pkl\",'rb') as file:\n",
    "    pp = pickle.loads(file.read())\n",
    "print('加载预处理meta完成。',flush=True)\n",
    "inputs = pp.transform(data)\n",
    "print(inputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.view(-1,2,inputs.shape[-1]).float() # L x B x I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "rnn = nn.LSTMCell(input_size=141, hidden_size=256, bidirectional=True) #input_size, hidden_size, num_layers\n",
    "# input: seq_len, batch, input_size\n",
    "# inputs = inputs.reshape(10,1,141).float()\n",
    "h0 = torch.randn(2, 2, 256)#num_layers * num_directions, batch, hidden_size\n",
    "c0 = torch.randn(2, 2, 256)#num_layers * num_directions, batch, hidden_size\n",
    "o = []\n",
    "for i in range(l):\n",
    "    if mask[i]:\n",
    "        o.append(rnn(inputs[i,:,:]))\n",
    "    else:\n",
    "        o.append(rnn(o[-1]))\n",
    "\n",
    "    \n",
    "output, (hn, cn) = rnn(inputs, (h0, c0)) # output: seq_len, batch, num_directions * hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(512, 141),\n",
    ")\n",
    "pred = net(output)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "loss = loss_func(pred,inputs)\n",
    "optimizer = torch.optim.Adam(, lr=0.001)\n",
    "net.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn_fw = torch.nn.LSTMCell(input_size=n_feature, hidden_size=n_hidden)\n",
    "        self.rnn_bw = torch.nn.LSTMCell(input_size=n_feature, hidden_size=n_hidden)\n",
    "        \n",
    "        self.predict = torch.nn.Linear(n_hidden*2, n_output)\n",
    "        \n",
    "    def merge(self,missing,pred,mask):\n",
    "        return missing + pred * mask\n",
    "        \n",
    "    def forward(self, x, is_train = True, mask = None):\n",
    "        #x : L x B x F\n",
    "        x_bw = x[::-1]\n",
    "        out = []\n",
    "        hx_fw = torch.randn(x.shape[1], x.shape[2]) # B x H\n",
    "        cx_fw = torch.randn(x.shape[1], x.shape[2])\n",
    "        hx_bw = torch.randn(x.shape[1], x.shape[2])\n",
    "        cx_bw = torch.randn(x.shape[1], x.shape[2])\n",
    "        if is_train:\n",
    "            for i in range(x.shape[0]):\n",
    "                hx_fw,cs_fw = self.rnn_fw(x[i],hx_fw,cs_fw)\n",
    "                hx_bw,cs_bw = self.rnn_bw(x_bw[i],hx_bw,cs_bw)\n",
    "                out.append(self.predict(torch.cat([hx_fw,hx_bw])))\n",
    "        else:\n",
    "            for i in range(x.shape[0]):\n",
    "                if not mask[i]: # 正常值\n",
    "                    hx_fw,cs_fw = self.rnn_fw(x[i],hx_fw,cs_fw)\n",
    "                else: #缺失值\n",
    "                    merge = self.merge(x[i],out[-1])\n",
    "                    hx_fw,cs_fw = self.rnn_fw(x[i],hx_fw,cs_fw)\n",
    "                if not mask[::-1][i]:\n",
    "                    hx_bw,cs_bw = self.rnn_bw(x[i],hx_bw,cs_bw)\n",
    "                else: #缺失值\n",
    "                    merge = self.merge(x_bw[i],out[-1])\n",
    "                    hx_fw,cs_fw = self.rnn_fw(x[i],hx_fw,cs_fw)\n",
    "                hx_bw,cs_bw = self.rnn_bw(x_bw[i],hx_bw,cs_bw)\n",
    "                out.append(self.predict(torch.cat([hx_fw,hx_bw])))\n",
    "        out = torch.tensor(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run RNN/exp2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run RNN/evalute2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run check_submit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%run utilities.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
